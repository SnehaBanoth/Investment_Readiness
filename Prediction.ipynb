{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Preprocessing as pp\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_selection import SelectPercentile, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and saving of preprocessed datasets\n",
    "\n",
    "Details in separate ``preprocessing.py`` script. This notebook requires the ``company_data.json`` and ``jobs_data.json`` in a folder titled ``data`` to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pp.get_final_dataset()\n",
    "pp.split_and_save(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset_train\", \"rb\") as file:\n",
    "    train_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset_test\", \"rb\") as file:\n",
    "    test_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting for different prediction tasks\n",
    "\n",
    "Separates the required X and Y datasets for the different attempted prediction tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_and_Y(dataset, prediction_task='last_funding_regression'):\n",
    "    \"\"\"\n",
    "    Since we're trying to do a few different prediction tasks, I thought to create this function that neatly makes\n",
    "    the right X and Y datasets. Input the prediction task:\n",
    "    'last_funding_regression' -- For the regression task that predicts how much funding a startup will get.\n",
    "    'funding_stage_classification' -- For predicting the type of funding round the startup will get (seed, series A, etc.)\n",
    "    'growth_stage_classification' -- For predicting what growth stage the startup is in, as suggested by Sarah's father.\n",
    "    \"\"\"\n",
    "    \n",
    "    last_funding_features = [col for col in dataset.columns if col.startswith('last_funding')]\n",
    "    last_funding_round_features = [col for col in dataset.columns if col.startswith('last_funding_round_round')]\n",
    "    growth_stage_features = [col for col in dataset.columns if col.startswith('growth_stage')]\n",
    "    \n",
    "    \n",
    "    X = dataset.drop(last_funding_features+growth_stage_features, axis=1)\n",
    "    \n",
    "    if prediction_task == 'last_funding_regression':\n",
    "        Y = dataset['last_funding']\n",
    "    elif prediction_task == 'funding_stage_classification':\n",
    "        Y = dataset[last_funding_round_features]\n",
    "    elif prediction_task == 'growth_stage_classification':\n",
    "        Y = dataset[growth_stage_features]\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = split_X_and_Y(train_data, 'funding_stage_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression, Y_train_regression = split_X_and_Y(train_data, 'last_funding_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[Y_train.columns[Y_train.sum()>100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers and feature selection\n",
    "\n",
    "For the classification task, uncommon classes were removed. \n",
    "For the regression task, companies with over â‚¬10 million in funding were removed.\n",
    "\n",
    "Features were selected from a combined analysis of the performances of the two predictive models and saved to a separate file imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[Y_train.sum(axis=1) == 1]\n",
    "Y_train = Y_train[Y_train.sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train_regression[Y_train_regression < 10]\n",
    "Y_train_regression = Y_train_regression[Y_train_regression < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features', 'rb') as file:\n",
    "    features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[features]\n",
    "x_regression = X_train_regression[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the models\n",
    "\n",
    "In both cases Random Forests turned out to give the best predictions. The models are defined with gridsearch to find the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()\n",
    "randomforest = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "randomforestregression = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "impute_select_randomforest_pipe = make_pipeline(imputer, randomforest)\n",
    "impute_randomforest_regression_pipe = make_pipeline(imputer, randomforestregression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(impute_select_randomforest_pipe, \n",
    "                          {'randomforestclassifier__min_samples_split':[2,3,4,5],\n",
    "                           'randomforestclassifier__max_features': [None],\n",
    "                          }, cv=3)\n",
    "\n",
    "gridsearch_regression = GridSearchCV(impute_randomforest_regression_pipe, \n",
    "                                     {'randomforestregressor__min_samples_split':[2,3,4,5],\n",
    "                                      'randomforestregressor__max_features': [None, 'auto', 0.5]\n",
    "                                     }, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gridsearch.fit(x, Y_train)\n",
    "gridsearch_regression.fit(x_regression, Y_train_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6630067128063694\n",
      "0.8824849452804691\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch.best_score_)\n",
    "print(gridsearch_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = split_X_and_Y(test_data, 'funding_stage_classification')\n",
    "X_test_regression, Y_test_regression = split_X_and_Y(test_data, 'last_funding_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test[Y_train.columns]\n",
    "X_test = X_test[Y_test.sum(axis=1) == 1]\n",
    "Y_test = Y_test[Y_test.sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_regression = X_test_regression[~Y_test_regression.isna()]\n",
    "Y_test_regression = Y_test_regression[~Y_test_regression.isna()]\n",
    "\n",
    "X_test_regression = X_test_regression[Y_test_regression < 10]\n",
    "Y_test_regression = Y_test_regression[Y_test_regression < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6609745939192003"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.score(X_test[features], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846728461676138"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_regression.score(X_test_regression[features], Y_test_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models for use in demo\n",
    "\n",
    "``demo.py`` implements the live demo, which imports the saved models from this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models\", \"wb\") as file:\n",
    "    pickle.dump((gridsearch, gridsearch_regression), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
